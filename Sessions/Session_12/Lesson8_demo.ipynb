{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lesson8_demo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "5HqrgWvM3bed"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "NlpURSyM3bYZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !pip install https://github.com/fastai/fastai/archive/master.zip\n",
        "!pip install fastai==0.7.0\n",
        "!pip install torchtext==0.2.3\n",
        "!pip install opencv-python\n",
        "!apt update && apt install -y libsm6 libxext6\n",
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "!pip3 install torchvision\n",
        "!mkdir data\n",
        "!wget http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar -P data/\n",
        "!wget https://storage.googleapis.com/coco-dataset/external/PASCAL_VOC.zip -P data/\n",
        "!tar -xf data/VOCtrainval_06-Nov-2007.tar -C data/\n",
        "!unzip data/PASCAL_VOC.zip -d data/\n",
        "!rm -rf data/PASCAL_VOC.zip data/VOCtrainval_06-Nov-2007.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kDro9L_e3fnB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k5kyN966-M2u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install Pillow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bc6FsNf_3bYg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from fastai.conv_learner import *\n",
        "from fastai.dataset import *\n",
        "\n",
        "from pathlib import Path\n",
        "import json\n",
        "#from PIL import ImageDraw, ImageFont\n",
        "import PIL\n",
        "from matplotlib import patches, patheffects\n",
        "#torch.cuda.set_device(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7YzZExfnCkfM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iKf9EqhfGU0_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OyR9qTTwGU3p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s_BnI5mUGb9P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eXa9-yYaGko6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p6D55EEY3bYo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Pascal VOC"
      ]
    },
    {
      "metadata": {
        "id": "AbO8vQLG3bYq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will be looking at the [Pascal VOC](http://host.robots.ox.ac.uk/pascal/VOC/) dataset. It's quite slow, so you may prefer to download from [this mirror](https://pjreddie.com/projects/pascal-voc-dataset-mirror/). There are two different competition/research datasets, from 2007 and 2012. We'll be using the 2007 version. You can use the larger 2012 for better results, or even combine them (but be careful to avoid data leakage between the validation sets if you do this).\n",
        "\n",
        "Unlike previous lessons, we are using the python 3 standard library `pathlib` for our paths and file access. Note that it returns an OS-specific class (on Linux, `PosixPath`) so your output may look a little different. Most libraries than take paths as input can take a pathlib object - although some (like `cv2`) can't, in which case you can use `str()` to convert it to a string."
      ]
    },
    {
      "metadata": {
        "id": "xOjBuxb03bYs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#PATH = Path('data/PASCAL_VOC')\n",
        "#list(PATH.iterdir())\n",
        "PATH = Path('data')\n",
        "list((PATH/'PASCAL_VOC').iterdir())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xYXyaz8MPu9e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# downloaded = files.download('data/PASCAL_VOC/pascal_train2007.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XVAuzMoq3bY7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As well as the images, there are also *annotations* - *bounding boxes* showing where each object is. These were hand labeled. The original version were in XML, which is a little hard to work with nowadays, so we uses the more recent JSON version which you can download from [this link](https://storage.googleapis.com/coco-dataset/external/PASCAL_VOC.zip).\n",
        "\n",
        "You can see here how `pathlib` includes the ability to open files (amongst many other capabilities)."
      ]
    },
    {
      "metadata": {
        "id": "N8qvcFhk3bY9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_json = json.load((PATH/'PASCAL_VOC'/'pascal_train2007.json').open()) # training_json is a dict\n",
        "training_json.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OsBviVGp-pu9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_json.items()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hIbcd0iAAoJh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print(list(training_json)[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7mSNyvrdqwm1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It's helpful to use constants instead of strings, since we get tab-completion and don't mistype."
      ]
    },
    {
      "metadata": {
        "id": "r2A4SlHO3bZC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "IMAGES,ANNOTATIONS,CATEGORIES = ['images', 'annotations', 'categories']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7HMJfgxiHB-b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_json[IMAGES][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1uPFvcHfHCJT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_json[ANNOTATIONS][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "90oGyKCYHCTA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_json[CATEGORIES][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bbMJKkfkrB4T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_json[IMAGES][:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YcIGyE7c3bZJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_json[ANNOTATIONS][:3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "emf99_z93bZO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_json[CATEGORIES][:20]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zc5tPDqo3bZW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "FILE_NAME,ID,IMG_ID,CATEGORY_ID,BBOX = 'file_name','id','image_id','category_id','bbox'\n",
        "\n",
        "categories = {o[ID]:o['name'] for o in training_json[CATEGORIES]}\n",
        "training_filenames = {o[ID]:o[FILE_NAME] for o in training_json[IMAGES]}\n",
        "training_ids = [o[ID] for o in training_json[IMAGES]]\n",
        "\n",
        "# categories and training_filenames are dicts || training_ids is a list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q2GcHfep6AOG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#training_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DTLhCfW-3bZb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "list((PATH/'VOCdevkit'/'VOC2007').iterdir())\n",
        "#list(('VOCdevkit'/'VOC2007').iterdir())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TDyc3_1f3bZg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "JPEGS = 'VOCdevkit/VOC2007/JPEGImages'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kg1ZSZHi3bZi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "IMG_PATH = PATH/JPEGS\n",
        "list(IMG_PATH.iterdir())[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "APFLZsPVGRHn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Each image has a unique ID."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b6VXwxOu3bZm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# A 'IMAGE' sample key-value pair -  [{'FILE_NAME': '000012.jpg', 'height': 333, 'ID': 12, 'width': 500},\n",
        "im0_d = training_json[IMAGES][0]\n",
        "im0_d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "myZ9WD-7GsVe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "im0_d[FILE_NAME],im0_d[ID] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lcCDNPS0Wq3a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Python's defaultdict is useful any time you want to have a default dictionary entry for new keys. If you try and access a key that doesnâ€™t exist, it magically makes itself exist and it sets itself equal to the return value of the function you specify (in this case lambda:[])."
      ]
    },
    {
      "metadata": {
        "id": "o-4cvaPS3bZq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# A 'ANNOTATION' sample key-value pair -\n",
        "# [{'area': 34104,\n",
        "#   'BBOX': [155, 96, 196, 174],\n",
        "#   'category_id': 7,\n",
        "#   'id': 1,\n",
        "#   'ignore': 0,\n",
        "#   'image_id': 12,\n",
        "#   'iscrowd': 0,\n",
        "#   'segmentation': [[155, 96, 155, 270, 351, 270, 351, 96]]},\n",
        " \n",
        "# x, y, width, height -> bottom-left coord (y, x), top-right coord (y+height-1, x+width-1)  \n",
        "  \n",
        "def hw_bb(bb): return np.array([bb[1], bb[0], bb[3]+bb[1]-1, bb[2]+bb[0]-1])\n",
        "\n",
        "training_annotations = collections.defaultdict(lambda:[])\n",
        "for o in training_json[ANNOTATIONS]:\n",
        "    if not o['ignore']:\n",
        "        bb = o[BBOX]\n",
        "        bb = hw_bb(bb)\n",
        "        training_annotations[o[IMG_ID]].append((bb,o[CATEGORY_ID]))\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fYlAR-SKOVSn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for o in training_json[ANNOTATIONS][:1]:\n",
        "    if not o['ignore']:\n",
        "        bb = o[BBOX]\n",
        "bb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5aBqxxFvO-v5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bb = hw_bb(bb)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6jBiTBHOPS5V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rw3bV5OiPPNn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_annotations[o[IMG_ID]].append((bb,o[CATEGORY_ID]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qcngcR60OVW0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(training_annotations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dnNtVgkpOC6A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "im_a = training_annotations[im0_d[ID]]; \n",
        "im_a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bw1hL3xLODxO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "im0_a = im_a[0]; im0_a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KeZZB0bG3bZ0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "categories[7]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Jdt6Toz3bZ3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_annotations[17]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E57Ankwb3bZ7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "categories[15],categories[13]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8wk4vzIu3bZ9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Some libs take VOC format bounding boxes, so this let's us convert back when required:"
      ]
    },
    {
      "metadata": {
        "id": "AEQnlqfI3bZ-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bb_voc = [155, 96, 196, 174]\n",
        "bb_fastai = hw_bb(bb_voc) # def hw_bb(bb): return np.array([bb[1], bb[0], bb[3]+bb[1]-1, bb[2]+bb[0]-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HyYnUUeo3baA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def bb_hw(a): return np.array([a[1],a[0],a[3]-a[1]+1,a[2]-a[0]+1]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3tTb_aph3baC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f'expected: {bb_voc}, actual: {bb_hw(bb_fastai)}'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mj9VL6_G3baG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "im = open_image(IMG_PATH/im0_d[FILE_NAME])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j6sFtZCn3baH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Matplotlib's `plt.subplots` is a really useful wrapper for creating plots, regardless of whether you have more than one subplot. Note that Matplotlib has an optional object-oriented API which I think is much easier to understand and use (although few examples online use it!)"
      ]
    },
    {
      "metadata": {
        "id": "avLa1ZOm3baJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show_img(im, figsize=None, ax=None):\n",
        "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
        "    ax.imshow(im)\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qUyWXSpy3baO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A simple but rarely used trick to making text visible regardless of background is to use white text with black outline, or visa versa. Here's how to do it in matplotlib."
      ]
    },
    {
      "metadata": {
        "id": "pwfUflnm3baP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def draw_outline(o, lw):\n",
        "    o.set_path_effects([patheffects.Stroke(\n",
        "        linewidth=lw, foreground='black'), patheffects.Normal()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8CcxTg0l3baS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that `*` in argument lists is the [splat operator](https://stackoverflow.com/questions/5239856/foggy-on-asterisk-in-python). In this case it's a little shortcut compared to writing out `b[-2],b[-1]`."
      ]
    },
    {
      "metadata": {
        "id": "-LGmq-it3baT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def draw_rect(ax, b):\n",
        "    patch = ax.add_patch(patches.Rectangle(b[:2], *b[-2:], fill=False, edgecolor='white', lw=2))\n",
        "    draw_outline(patch, 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BCaq6UcH3baW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def draw_text(ax, xy, txt, sz=14):\n",
        "    text = ax.text(*xy, txt,\n",
        "        verticalalignment='top', color='white', fontsize=sz, weight='bold')\n",
        "    draw_outline(text, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B-PAlX3B3baZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ax = show_img(im)\n",
        "b = bb_hw(im0_a[0])\n",
        "draw_rect(ax, b)\n",
        "draw_text(ax, b[:2], categories[im0_a[1]]) # b[:2] - > b[0] and b[1]... top left coordinates."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VkKlzO6w3bac",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def draw_im(im, ann):\n",
        "    ax = show_img(im, figsize=(16,8))\n",
        "    for b,c in ann:\n",
        "        b = bb_hw(b)\n",
        "        draw_rect(ax, b)\n",
        "        draw_text(ax, b[:2], categories[c], sz=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HnU4APwf3bae",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def draw_idx(i):\n",
        "    im_a = training_annotations[i]\n",
        "    im = open_image(IMG_PATH/training_filenames[i])\n",
        "    print(im.shape)\n",
        "    draw_im(im, im_a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uR3TtN543bah",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "draw_idx(17)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_HjjmnIx3bal",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Largest item classifier"
      ]
    },
    {
      "metadata": {
        "id": "uC-VHJn-3bal",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A *lambda function* is simply a way to define an anonymous function inline. Here we use it to describe how to sort the annotation for each image - by bounding box size (descending)."
      ]
    },
    {
      "metadata": {
        "id": "1WtFSKzM3bam",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#get largest\n",
        "def get_largest(b):\n",
        "    if not b: raise Exception()\n",
        "    b = sorted(b, key=lambda x: np.product(x[0][-2:]-x[0][:2]), reverse=True)\n",
        "    return b[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PwP4rhk8ek_s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = ([96, 155, 269, 350],16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lym_W-jaeo7M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RZm4NhDKepAm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x[0][-2:] # width x height of the bottom right bbox"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aWzNquLifnRf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x[0][:2]  # x & y coord of the top left bbox"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B3VuFbt3frII",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.product(x[0][-2:] - x[0][:2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E-MFFMMVmlUA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_annotations.items()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MiVnGwN0Ud-0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "Gfo687Vh3bap",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_largest_annotations = {a: get_largest(b) for a,b in training_annotations.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xx6gfUqGVH-N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_annotations[17]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O9eJ8hy5Vu0d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_largest_annotations[17]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HQl0vqjK3baq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we have a dictionary from image id to a single bounding box - the largest for that image."
      ]
    },
    {
      "metadata": {
        "id": "ZqYjqj6a3bar",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "b,c = training_largest_annotations[23]\n",
        "b = bb_hw(b)\n",
        "ax = show_img(open_image(IMG_PATH/training_filenames[23]), figsize=(5,10))\n",
        "draw_rect(ax, b)\n",
        "draw_text(ax, b[:2], categories[c], sz=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xB4vFCnP3bav",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(PATH/'tmp').mkdir(exist_ok=True)\n",
        "CSV = PATH/'tmp/lrg.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4KrvkRpb3bax",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Often it's easiest to simply create a CSV of the data you want to model, rather than trying to create a custom dataset. Here we use Pandas to help us create a CSV of the image filename and class."
      ]
    },
    {
      "metadata": {
        "id": "MuKUMLfP3bay",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# trn_fns = {o[ID]:o[FILE_NAME] for o in trn_j[IMAGES]}\n",
        "#fn - filename, cat - categories\n",
        "df = pd.DataFrame({'fn': [training_filenames[o] for o in training_ids],\n",
        "    'cat': [categories[training_largest_annotations[o][1]] for o in training_ids]}, columns=['fn','cat'])\n",
        "df.to_csv(CSV, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "08UgO6Ji3ba0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f_model = resnet34\n",
        "sz=224\n",
        "bs=64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-2oh3fwh3ba4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "From here it's just like Dogs vs Cats!"
      ]
    },
    {
      "metadata": {
        "id": "KovRdPcK3ba4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfms = tfms_from_model(f_model, sz, aug_tfms=transforms_side_on, crop_type=CropType.NO)\n",
        "md = ImageClassifierData.from_csv(PATH, JPEGS, CSV, tfms=tfms, bs=bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-slVSoce3ba6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x,y=next(iter(md.val_dl))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cafZqFNb3ba8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "show_img(md.val_ds.denorm(to_np(x))[0]);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "15NZoqm4yYAA",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn = ConvLearner.pretrained(f_model, md, metrics=[accuracy])\n",
        "learn.opt_fn = optim.Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v7OuFqFN3bbD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lrf=learn.lr_find(1e-5,100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OlvNi32d3bbG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "When you LR finder graph looks like this, you can ask for more points on each end:"
      ]
    },
    {
      "metadata": {
        "id": "gK1q_KKe3bbH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.sched.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a1HIkEe73bbJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.sched.plot(n_skip=5, n_skip_end=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xt6OE93f3bbM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr = 2e-2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XqWnk1Oj3bbO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lr, 1, cycle_len=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w2Ox5Akz3bbT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lrs = np.array([lr/1000,lr/100,lr])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HAjTeYKF3bbY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.freeze_to(-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IhGTyxQI3bbe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lrf=learn.lr_find(lrs/1000)\n",
        "learn.sched.plot(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rWogh50a3bbi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lrs/5, 1, cycle_len=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZzYXpF7w3bbn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.unfreeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pkJ55pyF3bbs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Accuracy isn't improving much - since many images have multiple different objects, it's going to be impossible to be that accurate."
      ]
    },
    {
      "metadata": {
        "id": "1wa17tCj3bbt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lrs/5, 1, cycle_len=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EXRsfEjU3bby",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save('clas_one')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "12-x_3UD3bb5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.load('clas_one')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-bKIGiETXsG3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Inside of a model data object, we have a bunch of things which include training data loader and training data set. The main thing to know about data loader is that it is an iterator that each time you grab the next iteration of stuff from it, you get a mini batch.\n",
        "\n",
        "If you want to grab just a single batch, this is how you do it:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# x: independent variable\n",
        "# y: dependent variable\n",
        "x, y = next(iter(md.val_dl))\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "bNM-yi793bb-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x,y = next(iter(md.val_dl))\n",
        "probs = F.softmax(predict_batch(learn.model, x), -1)\n",
        "x,preds = to_np(x),to_np(probs) # variables to numpy arrays\n",
        "preds = np.argmax(preds, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DAs3raPbZDyS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "preds\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G792LDz93bcE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(3, 4, figsize=(12, 8))\n",
        "for i,ax in enumerate(axes.flat):\n",
        "    ima=md.val_ds.denorm(x)[i]\n",
        "    b = md.classes[preds[i]]\n",
        "    ax = show_img(ima, ax=ax)\n",
        "    draw_text(ax, (0,0), b)\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jXkCRO3P3bcI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It's doing a pretty good job of classifying the largest object!"
      ]
    },
    {
      "metadata": {
        "id": "XLjIB2b73bcJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Bbox only"
      ]
    },
    {
      "metadata": {
        "id": "xZzkrz8K3bcK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we'll try to find the bounding box of the largest object. This is simply a regression with 4 outputs. So we can use a CSV with multiple 'labels'."
      ]
    },
    {
      "metadata": {
        "id": "Q7fmHXbE3bcM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BB_CSV = PATH/'tmp/bb.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ipdd2c4-3bcQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bb = np.array([training_largest_annotations[o][0] for o in training_ids])\n",
        "bbs = [' '.join(str(p) for p in o) for o in bb]\n",
        "\n",
        "df = pd.DataFrame({'fn': [training_filenames[o] for o in training_ids], 'bbox': bbs}, columns=['fn','bbox'])\n",
        "df.to_csv(BB_CSV, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hOEJWwFX3bcU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BB_CSV.open().readlines()[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jUToMQ2U3bcY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f_model=resnet34\n",
        "sz=224\n",
        "bs=64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O3NaOAZ43bcg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Set `continuous=True` to tell fastai this is a regression problem, which means it won't one-hot encode the labels, and will use MSE as the default crit.\n",
        "\n",
        "Note that we have to tell the transforms constructor that our labels are coordinates, so that it can handle the transforms correctly.\n",
        "\n",
        "Also, we use CropType.NO because we want to 'squish' the rectangular images into squares, rather than center cropping, so that we don't accidentally crop out some of the objects. (This is less of an issue in something like imagenet, where there is a single object to classify, and it's generally large and centrally located)."
      ]
    },
    {
      "metadata": {
        "id": "SMCGNTtD3bcg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "augs = [RandomFlip(), \n",
        "        RandomRotate(30),\n",
        "        RandomLighting(0.1,0.1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zktnGkM1GN-H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LZlzWapq3bcl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfms = tfms_from_model(f_model, sz, crop_type=CropType.NO, aug_tfms=augs)\n",
        "md = ImageClassifierData.from_csv(PATH, JPEGS, BB_CSV, tfms=tfms, continuous=True, bs=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vcXsR3eL3bcp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "idx=3\n",
        "fig,axes = plt.subplots(3,3, figsize=(9,9))\n",
        "for i,ax in enumerate(axes.flat):\n",
        "    x,y=next(iter(md.aug_dl))\n",
        "    ima=md.val_ds.denorm(to_np(x))[idx]\n",
        "    b = bb_hw(to_np(y[idx]))\n",
        "    print(b)\n",
        "    show_img(ima, ax=ax)\n",
        "    draw_rect(ax, b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F8AJcB2n3bc2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "augs = [RandomFlip(tfm_y=TfmType.COORD),\n",
        "        RandomRotate(30, tfm_y=TfmType.COORD),\n",
        "        RandomLighting(0.1,0.1, tfm_y=TfmType.COORD)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UwHnHwRW3bc5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfms = tfms_from_model(f_model, sz, crop_type=CropType.NO, tfm_y=TfmType.COORD, aug_tfms=augs)\n",
        "md = ImageClassifierData.from_csv(PATH, JPEGS, BB_CSV, tfms=tfms, continuous=True, bs=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hzcf1-y43bc9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "idx=3\n",
        "fig,axes = plt.subplots(3,3, figsize=(9,9))\n",
        "for i,ax in enumerate(axes.flat):\n",
        "    x,y=next(iter(md.aug_dl))\n",
        "    ima=md.val_ds.denorm(to_np(x))[idx]\n",
        "    b = bb_hw(to_np(y[idx]))\n",
        "    print(b)\n",
        "    show_img(ima, ax=ax)\n",
        "    draw_rect(ax, b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eoD0acrQa0p3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Note that we have to tell the transforms constructor that our labels are coordinates, so that it can handle the transforms correctly."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QWWOs06x3bdC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfm_y = TfmType.COORD\n",
        "augs = [RandomFlip(tfm_y=tfm_y),\n",
        "        RandomRotate(3, p=0.5, tfm_y=tfm_y),\n",
        "        RandomLighting(0.05,0.05, tfm_y=tfm_y)]\n",
        "\n",
        "tfms = tfms_from_model(f_model, sz, crop_type=CropType.NO, tfm_y=tfm_y, aug_tfms=augs)\n",
        "md = ImageClassifierData.from_csv(PATH, JPEGS, BB_CSV, tfms=tfms, bs=bs, continuous=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3iQGqP7m3bdG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "fastai let's you use a `custom_head` to add your own module on top of a convnet, instead of the adaptive pooling and fully connected net which is added by default. In this case, we don't want to do any pooling, since we need to know the activations of each grid cell.\n",
        "\n",
        "The final layer has 4 activations, one per bounding box coordinate. Our target is continuous, not categorical, so the MSE loss function used does not do any sigmoid or softmax to the module outputs."
      ]
    },
    {
      "metadata": {
        "id": "7D5Q-dzLb1Kg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Flatten()\n",
        "\n",
        "#The previous layer generally has 7x7x512 param in ResNet34, so flatten that out into a single vector."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YNY3f2V13bdH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "512*7*7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HQm9nRXo3bdJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "head_reg4 = nn.Sequential(Flatten(), nn.Linear(25088,4))\n",
        "learn = ConvLearner.pretrained(f_model, md, custom_head=head_reg4)\n",
        "learn.opt_fn = optim.Adam\n",
        "learn.crit = nn.L1Loss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xQG_IKXv3bdM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RmVKZnqL3bdS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.lr_find(1e-5,100)\n",
        "learn.sched.plot(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WO-DqJ5C3bdV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr = 2e-3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fADslrSk3bdW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lr, 2, cycle_len=1, cycle_mult=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "djNpAPU93bda",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lrs = np.array([lr/100,lr/10,lr])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J9vFgZjP3bdb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.freeze_to(-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x7Pl4lfV3bdc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lrf=learn.lr_find(lrs/1000)\n",
        "learn.sched.plot(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jYMsgdHh3bdf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lrs, 2, cycle_len=1, cycle_mult=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4bY_cgh03bdh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.freeze_to(-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VZx6XECN3bdj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lrs, 1, cycle_len=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "drEz3tge3bdk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save('reg4')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "__0JUgcv3bdm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.load('reg4')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hnq0scFr3bdn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x,y = next(iter(md.val_dl))\n",
        "learn.model.eval()\n",
        "preds = to_np(learn.model(VV(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WiDcbIv_3bdp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(3, 4, figsize=(12, 8))\n",
        "for i,ax in enumerate(axes.flat):\n",
        "    ima=md.val_ds.denorm(to_np(x))[i]\n",
        "    b = bb_hw(preds[i])\n",
        "    ax = show_img(ima, ax=ax)\n",
        "    draw_rect(ax, b)\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5rYmeqsw3bdq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Single object detection"
      ]
    },
    {
      "metadata": {
        "id": "Q0-cHqHK3bds",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f_model=resnet34\n",
        "sz=224\n",
        "bs=64\n",
        "\n",
        "val_idxs = get_cv_idxs(len(training_filenames))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D9il-fvI3bdt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfms = tfms_from_model(f_model, sz, crop_type=CropType.NO, tfm_y=TfmType.COORD, aug_tfms=augs)\n",
        "md = ImageClassifierData.from_csv(PATH, JPEGS, BB_CSV, tfms=tfms,\n",
        "   bs=bs, continuous=True, val_idxs=val_idxs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XlRxBsSg3bdu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "md2 = ImageClassifierData.from_csv(PATH, JPEGS, CSV, tfms=tfms_from_model(f_model, sz))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AqP4yliD3bdv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A dataset can be anything with `__len__` and `__getitem__`. Here's a dataset that adds a 2nd label to an existing dataset:"
      ]
    },
    {
      "metadata": {
        "id": "UEecbfS-3bdv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ConcatLblDataset(Dataset):\n",
        "    def __init__(self, ds, y2): self.ds,self.y2 = ds,y2\n",
        "    def __len__(self): return len(self.ds)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        x,y = self.ds[i]\n",
        "        return (x, (y,self.y2[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "udGOJzIs3bdx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We'll use it to add the classes to the bounding boxes labels."
      ]
    },
    {
      "metadata": {
        "id": "1JsRno3K3bdx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trn_ds2 = ConcatLblDataset(md.trn_ds, md2.trn_y)\n",
        "val_ds2 = ConcatLblDataset(md.val_ds, md2.val_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EZiQFj0D3bdz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_ds2[0][1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qc9mlCOR3bd1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can replace the dataloaders' datasets with these new ones."
      ]
    },
    {
      "metadata": {
        "id": "LiIJR0dC3bd2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "md.trn_dl.dataset = trn_ds2\n",
        "md.val_dl.dataset = val_ds2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CJy-PYxV3bd3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have to `denorm`alize the images from the dataloader before they can be plotted."
      ]
    },
    {
      "metadata": {
        "id": "B_KQNp6e3bd4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x,y=next(iter(md.val_dl))\n",
        "idx=3\n",
        "ima=md.val_ds.ds.denorm(to_np(x))[idx]\n",
        "b = bb_hw(to_np(y[0][idx])); b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J4uzO6uu3bd6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ax = show_img(ima)\n",
        "draw_rect(ax, b)\n",
        "draw_text(ax, b[:2], md2.classes[y[1][idx]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G5ayuTXr3bd8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We need one output activation for each class (for its probability) plus one for each bounding box coordinate. We'll use an extra linear layer this time, plus some dropout, to help us train a more flexible model."
      ]
    },
    {
      "metadata": {
        "id": "ZuFh29Om3bd8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "head_reg4 = nn.Sequential(\n",
        "    Flatten(),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(25088,256),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm1d(256),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(256,4+len(categories)),\n",
        ")\n",
        "models = ConvnetBuilder(f_model, 0, 0, 0, custom_head=head_reg4)\n",
        "\n",
        "learn = ConvLearner(md, models)\n",
        "learn.opt_fn = optim.Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QCHvdyQE3bd_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def detn_loss(input, target):\n",
        "    bb_t,c_t = target\n",
        "    bb_i,c_i = input[:, :4], input[:, 4:]\n",
        "    bb_i = F.sigmoid(bb_i)*224\n",
        "    # I looked at these quantities separately first then picked a multiplier\n",
        "    #   to make them approximately equal\n",
        "    return F.l1_loss(bb_i, bb_t) + F.cross_entropy(c_i, c_t)*20\n",
        "\n",
        "def detn_l1(input, target):\n",
        "    bb_t,_ = target\n",
        "    bb_i = input[:, :4]\n",
        "    bb_i = F.sigmoid(bb_i)*224\n",
        "    return F.l1_loss(V(bb_i),V(bb_t)).data\n",
        "\n",
        "def detn_acc(input, target):\n",
        "    _,c_t = target\n",
        "    c_i = input[:, 4:]\n",
        "    return accuracy(c_i, c_t)\n",
        "\n",
        "learn.crit = detn_loss\n",
        "learn.metrics = [detn_acc, detn_l1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pww6_AVK3beB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.lr_find()\n",
        "learn.sched.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9CA5ei_N3beC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr=1e-2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YtQbtMOT3beD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lr, 1, cycle_len=3, use_clr=(32,5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qB2s5W6I3beH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save('reg1_0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R6TV-fG-3beI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.freeze_to(-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uv3-SBPd3beK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lrs = np.array([lr/100, lr/10, lr])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UmoilWp73beM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.lr_find(lrs/1000)\n",
        "learn.sched.plot(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-EmHTJtt3beP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lrs/5, 1, cycle_len=5, use_clr=(32,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DX2A7mUi3beR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save('reg1_1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c4m3rJkM3beS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.load('reg1_1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7Yxr6jPL3beU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.unfreeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3UNwyI2J3beV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lrs/10, 1, cycle_len=10, use_clr=(32,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lKUa-R7H3beY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save('reg1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KCP9qeMK3beZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.load('reg1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wX9tJHU-3bea",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y = learn.predict()\n",
        "x,_ = next(iter(md.val_dl))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "408rmNAT3bec",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from scipy.special import expit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0idZld2Q3bec",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(3, 4, figsize=(12, 8))\n",
        "for i,ax in enumerate(axes.flat):\n",
        "    ima=md.val_ds.ds.denorm(to_np(x))[i]\n",
        "    bb = expit(y[i][:4])*224\n",
        "    b = bb_hw(bb)\n",
        "    c = np.argmax(y[i][4:])\n",
        "    ax = show_img(ima, ax=ax)\n",
        "    draw_rect(ax, b)\n",
        "    draw_text(ax, b[:2], md2.classes[c])\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5HqrgWvM3bed",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## End"
      ]
    },
    {
      "metadata": {
        "id": "NDo3OVHX3bed",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f_qluoO0kG-U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bb_voc = [155, 96, 196, 174]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZPfi5Jo_kG7m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bb_voc[:2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6H_qJqf3kG5O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}